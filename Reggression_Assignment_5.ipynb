{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9B_EK4Me9ix"
      },
      "outputs": [],
      "source": [
        "# Q1. What is Elastic Net Regression and How Does It Differ from Other Regression Techniques?\n",
        "# Elastic Net Regression is a linear regression model that combines both L1 (Lasso) and L2 (Ridge) regularization.\n",
        "# It aims to find a balance between Lasso and Ridge by incorporating both penalties in the loss function:\n",
        "# Loss function = RSS (Residual Sum of Squares) + λ1 * (sum of absolute values of coefficients) + λ2 * (sum of squared coefficients)\n",
        "# Elastic Net is particularly useful when there are highly correlated predictors. It can perform feature selection like Lasso and handle multicollinearity like Ridge.\n",
        "# Elastic Net is more flexible than either Lasso or Ridge because it can adjust the relative importance of the L1 and L2 penalties using a mixing parameter α.\n",
        "# - α = 1 corresponds to Lasso (only L1 regularization),\n",
        "# - α = 0 corresponds to Ridge (only L2 regularization),\n",
        "# - A value between 0 and 1 mixes both Lasso and Ridge regularization.\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "import numpy as np\n",
        "\n",
        "# Example of Elastic Net Regression\n",
        "X = np.array([[1], [2], [3], [4], [5]])  # Independent variable\n",
        "y = np.array([1, 2, 3, 4, 5])            # Dependent variable\n",
        "\n",
        "elastic_net_model = ElasticNet(alpha=0.1, l1_ratio=0.5)  # alpha is the regularization strength, l1_ratio mixes Lasso and Ridge\n",
        "elastic_net_model.fit(X, y)\n",
        "print(f\"Elastic Net Coefficients: {elastic_net_model.coef_}\")\n",
        "\n",
        "# Q2. How Do You Choose the Optimal Values of the Regularization Parameters for Elastic Net Regression?\n",
        "# The two key hyperparameters in Elastic Net are:\n",
        "# 1. **alpha (λ)**: Controls the overall strength of the regularization (both L1 and L2). A larger alpha increases the regularization.\n",
        "# 2. **l1_ratio**: Determines the balance between Lasso (L1) and Ridge (L2) regularization. When l1_ratio = 1, Elastic Net becomes equivalent to Lasso, and when l1_ratio = 0, it becomes equivalent to Ridge.\n",
        "# To find the optimal values of alpha and l1_ratio, you can use cross-validation, grid search, or randomized search.\n",
        "# The goal is to minimize the model’s error while avoiding overfitting by choosing the best regularization parameters.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Example: Grid search for optimal alpha and l1_ratio values\n",
        "parameters = {'alpha': [0.01, 0.1, 1, 10], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
        "elastic_net_grid = GridSearchCV(ElasticNet(), parameters, cv=5)\n",
        "elastic_net_grid.fit(X, y)\n",
        "print(f\"Best parameters: {elastic_net_grid.best_params_}\")\n",
        "\n",
        "# Q3. What Are the Advantages and Disadvantages of Elastic Net Regression?\n",
        "# Advantages:\n",
        "# - **Feature selection and regularization**: Elastic Net combines the benefits of Lasso (feature selection) and Ridge (handling multicollinearity).\n",
        "# - **Flexibility**: By adjusting the l1_ratio, Elastic Net can balance between Lasso and Ridge, making it more flexible than either technique alone.\n",
        "# - **Multicollinearity**: Elastic Net works well when there are highly correlated predictors.\n",
        "# Disadvantages:\n",
        "# - **More hyperparameters**: Elastic Net has more hyperparameters (alpha and l1_ratio), which can make tuning more complex.\n",
        "# - **Interpretation**: Since both L1 and L2 penalties are applied, interpreting the coefficients can be more difficult than in Lasso or Ridge alone.\n",
        "\n",
        "# Q4. What Are Some Common Use Cases for Elastic Net Regression?\n",
        "# Elastic Net is commonly used in the following scenarios:\n",
        "# - **High-dimensional data**: When the number of predictors (features) is greater than the number of observations, such as in genomics or text analysis.\n",
        "# - **Multicollinearity**: When independent variables are highly correlated, Elastic Net can handle this by balancing Lasso and Ridge penalties.\n",
        "# - **Feature selection**: In cases where you want to automatically select important features from a large set of variables.\n",
        "\n",
        "# Q5. How Do You Interpret the Coefficients in Elastic Net Regression?\n",
        "# The coefficients in Elastic Net can be interpreted similarly to those in Lasso or Ridge regression:\n",
        "# - **A positive coefficient** means that as the independent variable increases, the dependent variable increases.\n",
        "# - **A negative coefficient** means that as the independent variable increases, the dependent variable decreases.\n",
        "# The key difference is that the coefficients may be shrunken (via the regularization) and some may be zero, depending on the value of alpha and l1_ratio.\n",
        "\n",
        "# Example interpretation\n",
        "print(f\"Elastic Net Intercept: {elastic_net_model.intercept_}\")\n",
        "print(f\"Elastic Net Coefficients: {elastic_net_model.coef_}\")\n",
        "\n",
        "# Q6. How Do You Handle Missing Values When Using Elastic Net Regression?\n",
        "# Elastic Net Regression, like most regression models, cannot handle missing values directly.\n",
        "# You need to preprocess the data and handle missing values before fitting the model.\n",
        "# Common techniques include:\n",
        "# - **Imputation**: Fill in missing values with the mean, median, or mode of the respective feature.\n",
        "# - **Removal**: Remove rows or columns with missing values (if the missing data is sparse).\n",
        "# - **Advanced Imputation**: Use algorithms like KNN imputation or regression imputation for more sophisticated handling of missing values.\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Example: Imputing missing values with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Q7. How Do You Use Elastic Net Regression for Feature Selection?\n",
        "# Elastic Net can be used for feature selection as it combines the L1 (Lasso) penalty, which can shrink some coefficients to zero.\n",
        "# The features corresponding to non-zero coefficients are the selected features.\n",
        "# By adjusting the alpha and l1_ratio parameters, Elastic Net automatically selects important features by eliminating irrelevant ones.\n",
        "\n",
        "# Example: Check which features are selected (non-zero coefficients)\n",
        "print(f\"Selected Features (Non-Zero Coefficients): {elastic_net_model.coef_ != 0}\")\n",
        "\n",
        "# Q8. How Do You Pickle and Unpickle a Trained Elastic Net Regression Model in Python?\n",
        "# Pickling is a process of serializing Python objects, including trained machine learning models, so they can be saved and later loaded for inference.\n",
        "# You can use Python's `pickle` module to pickle (save) and unpickle (load) a trained Elastic Net model.\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Pickling (saving the trained model)\n",
        "with open('elastic_net_model.pkl', 'wb') as file:\n",
        "    pickle.dump(elastic_net_model, file)\n",
        "\n",
        "# Unpickling (loading the trained model)\n",
        "with open('elastic_net_model.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n",
        "# Use the unpickled model for predictions\n",
        "print(f\"Predictions with Unpickled Model: {loaded_model.predict(X)}\")\n",
        "\n",
        "# Q9. What is the Purpose of Pickling a Model in Machine Learning?\n",
        "# The purpose of pickling a machine learning model is to save it for later use. This allows you to:\n",
        "# 1. **Avoid retraining**: If you have already trained a model and achieved a good performance, you can pickle it to avoid retraining from scratch.\n",
        "# 2. **Model deployment**: Pickling is commonly used to save models for deployment in production environments.\n",
        "# 3. **Model sharing**: You can share a pickled model with other team members or use it in different applications.\n",
        "\n"
      ]
    }
  ]
}